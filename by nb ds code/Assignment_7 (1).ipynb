{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f59e82c",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8441042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db73b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello this a sample text. Where are you from?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece3feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello this a sample text.', 'Where are you from?']\n"
     ]
    }
   ],
   "source": [
    "tokens_sents = nltk.sent_tokenize(text)\n",
    "print(tokens_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e861e865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'this', 'a', 'sample', 'text', '.', 'Where', 'are', 'you', 'from', '?']\n"
     ]
    }
   ],
   "source": [
    "tokens_words = nltk.word_tokenize(text)\n",
    "print(tokens_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092e154",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6953c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da1acabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'civil'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "word = (\"civilization\")\n",
    "ps.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "653ca096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worker'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"Workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8bb45d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'construct'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(language = \"english\")\n",
    "stemmer.stem(\"Construction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a10e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'random'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"Randomly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e971bf",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "350de0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44adfa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker\n",
      "beach\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"workers\"))\n",
    "print(lemmatizer.lemmatize(\"beaches\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418cb7b",
   "metadata": {},
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c888cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech:  [('The', 'DT'), ('striped', 'JJ'), ('bats', 'NNS'), ('are', 'VBP'), ('hanging', 'VBG'), ('on', 'IN'), ('their', 'PRP$'), ('feet', 'NNS'), ('for', 'IN'), ('best', 'JJS')]\n"
     ]
    }
   ],
   "source": [
    "text = \"The striped bats are hanging on their feet for best\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(\"Parts of Speech: \",nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b3c4fd",
   "metadata": {},
   "source": [
    "# Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45fd5594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85a2bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Ich habe ein bisschen deutsch lernen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c86ad5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e4b696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text without stop words: bisschen deutsch lernen\n"
     ]
    }
   ],
   "source": [
    "english_stopwords = stopwords.words('german')\n",
    "\n",
    "tokens_wo_stopwords = [t for t in tokens if t not in english_stopwords]\n",
    "\n",
    "print(\"Text without stop words:\", \" \".join(tokens_wo_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a845c",
   "metadata": {},
   "source": [
    "# Term Frequency & Inverse Document Frequency\n",
    "\n",
    "---> term frequency(t,d) = count of term in document / number of words in document\n",
    "\n",
    "---> inverse document frequency(t) = log(total numbers of words / occurrence of term in documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fbb8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9364209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = 'Nothing ever goes as planned in this accursed world.'\n",
    "d1 = 'The longer you live, the more you realize that the only things that truly exist in this reality are merely pain, suffering and futility.'\n",
    "d2 = 'Listen, everywhere you look in this world, wherever there is light, there will always be shadows to be found as well.'\n",
    "\n",
    "string = [d0, d1, d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b21d0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "result = tfidf.fit_transform(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df55df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word indexes:\n",
      "{'nothing': 21, 'ever': 6, 'goes': 11, 'as': 4, 'planned': 24, 'in': 12, 'this': 33, 'accursed': 0, 'world': 39, 'the': 30, 'longer': 17, 'you': 40, 'live': 16, 'more': 20, 'realize': 26, 'that': 29, 'only': 22, 'things': 32, 'truly': 35, 'exist': 8, 'reality': 25, 'are': 3, 'merely': 19, 'pain': 23, 'suffering': 28, 'and': 2, 'futility': 10, 'listen': 15, 'everywhere': 7, 'look': 18, 'wherever': 37, 'there': 31, 'is': 13, 'light': 14, 'will': 38, 'always': 1, 'be': 5, 'shadows': 27, 'to': 34, 'found': 9, 'well': 36}\n",
      "\n",
      "tf-idf value:\n",
      "  (0, 39)\t0.29048754376040503\n",
      "  (0, 0)\t0.38195621126357737\n",
      "  (0, 33)\t0.22558949136203243\n",
      "  (0, 12)\t0.22558949136203243\n",
      "  (0, 24)\t0.38195621126357737\n",
      "  (0, 4)\t0.29048754376040503\n",
      "  (0, 11)\t0.38195621126357737\n",
      "  (0, 6)\t0.38195621126357737\n",
      "  (0, 21)\t0.38195621126357737\n",
      "  (1, 10)\t0.17957271370263975\n",
      "  (1, 2)\t0.17957271370263975\n",
      "  (1, 28)\t0.17957271370263975\n",
      "  (1, 23)\t0.17957271370263975\n",
      "  (1, 19)\t0.17957271370263975\n",
      "  (1, 3)\t0.17957271370263975\n",
      "  (1, 25)\t0.17957271370263975\n",
      "  (1, 8)\t0.17957271370263975\n",
      "  (1, 35)\t0.17957271370263975\n",
      "  (1, 32)\t0.17957271370263975\n",
      "  (1, 22)\t0.17957271370263975\n",
      "  (1, 29)\t0.3591454274052795\n",
      "  (1, 26)\t0.17957271370263975\n",
      "  (1, 20)\t0.17957271370263975\n",
      "  (1, 16)\t0.17957271370263975\n",
      "  (1, 40)\t0.2731393546778773\n",
      "  (1, 17)\t0.17957271370263975\n",
      "  (1, 30)\t0.5387181411079193\n",
      "  (1, 33)\t0.10605853747649555\n",
      "  (1, 12)\t0.10605853747649555\n",
      "  (2, 36)\t0.21113378986646478\n",
      "  (2, 9)\t0.21113378986646478\n",
      "  (2, 34)\t0.21113378986646478\n",
      "  (2, 27)\t0.21113378986646478\n",
      "  (2, 5)\t0.42226757973292955\n",
      "  (2, 1)\t0.21113378986646478\n",
      "  (2, 38)\t0.21113378986646478\n",
      "  (2, 14)\t0.21113378986646478\n",
      "  (2, 13)\t0.21113378986646478\n",
      "  (2, 31)\t0.42226757973292955\n",
      "  (2, 37)\t0.21113378986646478\n",
      "  (2, 18)\t0.21113378986646478\n",
      "  (2, 7)\t0.21113378986646478\n",
      "  (2, 15)\t0.21113378986646478\n",
      "  (2, 40)\t0.16057268926256973\n",
      "  (2, 39)\t0.16057268926256973\n",
      "  (2, 33)\t0.12469901748094937\n",
      "  (2, 12)\t0.12469901748094937\n",
      "  (2, 4)\t0.16057268926256973\n"
     ]
    }
   ],
   "source": [
    "print('\\nWord indexes:')\n",
    "print(tfidf.vocabulary_)\n",
    " \n",
    "# display tf-idf values\n",
    "print('\\ntf-idf value:')\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
